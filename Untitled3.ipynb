{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBB8wVsAW4uQ"
      },
      "outputs": [],
      "source": [
        "#########################################################################\n",
        "# Step 1: System takes a screenshot of a webpage\n",
        "#########################################################################\n",
        "# pip install Pillow\n",
        "# pip install selenium\n",
        "\n",
        "from selenium import webdriver\n",
        "from PIL import Image\n",
        "\n",
        "# Define the URL of the web page we want to screenshot\n",
        "\n",
        "url = 'https://finance.yahoo.com/quote/AAPL?p=AAPL&.tsrc=fin-srch'\n",
        "\n",
        "# Define the path to the webdriver executable (e.g., chromedriver.exe)\n",
        "\n",
        "# webdriver_path = '/path/to/webdriver/executable'\n",
        "webdriver_path = 'C:\\amit.la\\WIP\\RPA\\downloads\\chromedriver.exe'\n",
        "\n",
        "# Set up the webdriver\n",
        "\n",
        "options = webdriver.ChromeOptions()\n",
        "options.headless = True # Run the browser in headless mode to prevent a window from popping up\n",
        "driver = webdriver.Chrome(executable_path=webdriver_path, options=options)\n",
        "\n",
        "# Load the web page\n",
        "\n",
        "driver.get(url)\n",
        "\n",
        "# Take a screenshot of the entire page\n",
        "\n",
        "# screenshot = driver.find_element_by_tag_name('body').screenshot_as_png\n",
        "screenshot = driver.save_screenshot('../downloads/screenshot.png')\n",
        "\n",
        "# Close the webdriver\n",
        "\n",
        "driver.quit()\n",
        "\n",
        "# Save the screenshot to a file\n",
        "\n",
        "# with open('../SampleData/screenshot.png', 'wb') as file:\n",
        "#     file.write(screenshot)\n",
        "\n",
        "# Open the screenshot with Pillow to display it (optional)\n",
        "\n",
        "img = Image.open('../downloads/screenshot.png')\n",
        "img.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#########################################################################\n",
        "# Step 1: A receipt or invoice document is uploaded / dropped to a folder\n",
        "#########################################################################\n",
        "\n",
        "#   $ sftp remote_username@server_ip_or_hostname\n",
        "# >> Connected to remote_username@server_ip_or_hostname.\n",
        "\n",
        "# $ sftp> pwd\n",
        "# >> Remote working directory: /home/remote_username\n",
        "\n",
        "# $ sftp> lpwd\n",
        "# >> Local working directory: /downloads\n",
        "\n",
        "# $ sftp> put screenshot.png\n",
        "\n",
        "\n",
        "## TAKING A SCREENSHOT ##"
      ],
      "metadata": {
        "id": "HxeSNnIwXO6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##############################################################################\n",
        "# Step 2: Automated Code to call script is executed as soon as file is dropped\n",
        "##############################################################################\n",
        "import time\n",
        "import os\n",
        "\n",
        "# Define the directory to watch\n",
        "\n",
        "watch_dir = '/downloads/AAPL.png'\n",
        "\n",
        "# Define the command to run when a new file is added\n",
        "\n",
        "command = 'python c:/amit.la/WIP/RPA/ocr.py'\n",
        "\n",
        "# Define the set of already seen files\n",
        "\n",
        "seen_files = set()\n",
        "\n",
        "# Start watching the directory for new files\n",
        "\n",
        "while True:\n",
        "    # Get the list of files in the directory\n",
        "    files = os.listdir(watch_dir)\n",
        "\n",
        "    # Check each file in the directory\n",
        "    for file in files:\n",
        "        # If the file is new, trigger the command\n",
        "        if file not in seen_files:\n",
        "            seen_files.add(file)\n",
        "            os.system(command) # add to your DB...\n",
        "\n",
        "    # Wait for a little bit before checking again\n",
        "    time.sleep(10)"
      ],
      "metadata": {
        "id": "PqCDx3dOXRoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################\n",
        "# Step 3: Scripts read text from images\n",
        "#######################################\n",
        "# py -m pip install pytesseract : open source\n",
        "# py -m pip install PIL\n",
        "\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "\n",
        "##############################################################################\n",
        "# in case if tesseract is not included in PATH\n",
        "pytesseract.pytesseract.tesseract_cmd = r'C:\\amit.la\\WIP\\RPA\\downloads\\ts\\tesseract.exe'\n",
        "##############################################################################\n",
        "\n",
        "def read_image_text(image_path):\n",
        "    \"\"\"\n",
        "    Reads text from an image file using Tesseract OCR.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): The file path to the input image.\n",
        "\n",
        "    Returns:\n",
        "        str: The extracted text from the image.\n",
        "    \"\"\"\n",
        "    # Load the image file\n",
        "    image = Image.open(image_path)\n",
        "\n",
        "    # Use Tesseract OCR to extract the text from the image\n",
        "    text = pytesseract.image_to_string(image)\n",
        "\n",
        "    return text\n",
        "\n",
        "# Example usage\n",
        "image_path = \"../downloads/AAPL.png\"\n",
        "# image_path = \"../downloads/medical_form.png\"\n",
        "# image_path = \"../downloads/email.png\"\n",
        "# image_path = \"../downloads/vaccine.png\"\n",
        "# image_path = \"../downloads/blurry_1.png\"\n",
        "# image_path = \"../downloads/blurry_2.png\"\n",
        "text = read_image_text(image_path)\n",
        "print(text)"
      ],
      "metadata": {
        "id": "QDDJPjQUXVdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################\n",
        "# Step 4: Scripts to build prompts\n",
        "#######################################\n",
        "\n",
        "promptText = read_image_text(image_path)\n",
        "print(promptText)"
      ],
      "metadata": {
        "id": "Eg5ucUnKXYoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################\n",
        "# Step 5: Send prompts to Llama 2 | ChatGPT\n",
        "###########################################\n",
        "\n",
        "def callChatGPT(prompt):\n",
        "    ###########################################\n",
        "    # uncomment this code to call ChatGPT API #\n",
        "    ###########################################\n",
        "    # completion = openai.ChatCompletion.create(\n",
        "    # model=model_engine,\n",
        "    # messages=[\n",
        "    #     {\"role\": \"user\", \"content\": prompt}\n",
        "    # ])\n",
        "    # return completion.choices[0].message.content\n",
        "    return \"Yes\"\n",
        "\n",
        "def callLlama(prompt):\n",
        "    ###########################################\n",
        "    # uncomment this code to call Llama API #\n",
        "    ###########################################\n",
        "    # results = generator.chat_completion(\n",
        "    #     dialogs,  # type: ignore\n",
        "    #     max_gen_len=max_gen_len,\n",
        "    #     temperature=temperature,\n",
        "    #     top_p=top_p,\n",
        "    # )\n",
        "    # return result['generation']['content']\n",
        "    return \"Yes\"\n",
        "\n",
        "# build dynamic prompt per use case\n",
        "\n",
        "\n",
        "prompt = \"respond in one word: average volume of stock in this text.\"\n",
        "prompt += promptText\n"
      ],
      "metadata": {
        "id": "eNtZDH3GXbPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(promptText)\n",
        "print(prompt)"
      ],
      "metadata": {
        "id": "WIhy3s0QXeki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################\n",
        "# Step 6: Store results back to Application\n",
        "###########################################\n",
        "# res2 = callLlama(promptText)\n",
        "# res = callChatGPT(prompt)\n",
        "# res2 = callLlama(promptText)\n",
        "# res = 70,701,586\n",
        "print(res2)\n",
        "\n",
        "# response"
      ],
      "metadata": {
        "id": "76GNRBOhYL9E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}